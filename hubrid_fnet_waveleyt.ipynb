{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                              \n",
    "import torch.nn as nn                      \n",
    "import torch.optim as optim                \n",
    "from torch.utils.data import DataLoader    \n",
    "import torchvision                       \n",
    "import torchvision.transforms as transforms \n",
    "import numpy as np                         \n",
    "import cv2                                \n",
    "from skimage.metrics import structural_similarity as ssim  \n",
    "import matplotlib.pyplot as plt           \n",
    "import time\n",
    "from pytorch_wavelets import DWT, IDWT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(denoised, ground_truth):\n",
    "    mse = np.mean((denoised - ground_truth) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    PIXEL_MAX = 1.0 \n",
    "    psnr = 20 * np.log10(PIXEL_MAX / np.sqrt(mse))\n",
    "    return psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "\n",
    "def calculate_ssim(denoised, ground_truth):\n",
    "    return ssim(ground_truth, denoised, data_range=ground_truth.max() - ground_truth.min(), win_size=7, channel_axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download and load the CIFAR-10 training and test datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader  = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.fft import fft2, ifft2\n",
    "from pytorch_wavelets import DWT, IDWT\n",
    "\n",
    "\n",
    "class FNetBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatial-frequency mixing via FFT, with residual feed-forward.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, height, width):\n",
    "        super().__init__()\n",
    "        # Normalize across [C, H, W]\n",
    "        self.layer_norm = nn.LayerNorm([channels, height, width])\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels, channels, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # FFT and inverse FFT to mix spatial information globally\n",
    "        x_fft = fft2(x, dim=(-2, -1))\n",
    "        x_ifft = ifft2(x_fft, dim=(-2, -1)).real\n",
    "        # Residual feed-forward\n",
    "        x_norm = self.layer_norm(x_ifft)\n",
    "        return x_ifft + self.ffn(x_norm)\n",
    "\n",
    "\n",
    "class WaveletBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Predicts residual noise in the wavelet domain using single-level DWT.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, wavelet='haar'):\n",
    "        super().__init__()\n",
    "        self.dwt = DWT(J=1, wave=wavelet)\n",
    "        self.idwt = IDWT(wave=wavelet)\n",
    "        # FFN in wavelet domain (4 subbands concatenated)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Conv2d(4 * channels, 4 * channels, kernel_size=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4 * channels, 4 * channels, kernel_size=1, padding=0),\n",
    "        )\n",
    "        self.threshold = nn.Parameter(torch.zeros(3, channels, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Decompose\n",
    "        ll, yh = self.dwt(x)\n",
    "        detail = yh[0]               # [B, C, 3, H/2, W/2]\n",
    "        lh, hl, hh = torch.unbind(detail, dim=2)\n",
    "        # Process\n",
    "        stacked = torch.cat([ll, lh, hl, hh], dim=1)\n",
    "        y = self.ffn(stacked)\n",
    "        # Split back\n",
    "        c = x.size(1)\n",
    "        ll2, lh2, hl2, hh2 = torch.split(y, c, dim=1)\n",
    "        t = torch.sigmoid(self.threshold)\n",
    "        lh2 = lh2 * t[0]\n",
    "        hl2 = hl2 * t[1]\n",
    "        hh2 = hh2 * t[2]\n",
    "        y_high = torch.stack([lh2, hl2, hh2], dim=2)\n",
    "        # Reconstruct noise residual\n",
    "        out = self.idwt((ll2, [y_high]))\n",
    "        return out\n",
    "\n",
    "\n",
    "class DnCNNBranch(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard DnCNN residual noise predictor.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels=3, num_layers=17, features=64):\n",
    "        super().__init__()\n",
    "        layers = [nn.Conv2d(channels, features, kernel_size=3, padding=1, bias=True),\n",
    "                  nn.ReLU(inplace=True)]\n",
    "        for _ in range(num_layers - 2):\n",
    "            layers += [nn.Conv2d(features, features, 3, padding=1, bias=False),\n",
    "                       nn.BatchNorm2d(features),\n",
    "                       nn.ReLU(inplace=True)]\n",
    "        layers.append(nn.Conv2d(features, channels, 3, padding=1, bias=False))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class HybridTriBranchModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Hybrid denoiser combining DnCNN, FNet, and Wavelet residual branches.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 channels=3,\n",
    "                 height=32,\n",
    "                 width=32,\n",
    "                 dncnn_layers=17,\n",
    "                 dncnn_features=64,\n",
    "                 fnet_blocks=5,\n",
    "                 wavelet='haar'):\n",
    "        super().__init__()\n",
    "        # Branches\n",
    "        self.dncnn_branch = DnCNNBranch(channels, dncnn_layers, dncnn_features)\n",
    "        self.fnet_blocks = nn.Sequential(\n",
    "            *[FNetBlock(dncnn_features, height, width) for _ in range(fnet_blocks)]\n",
    "        )\n",
    "        self.wavelet_branch = WaveletBlock(channels, wavelet)\n",
    "        # Fusion conv: combines 3 residual estimates\n",
    "        self.fusion = nn.Conv2d(channels * 3, channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Predict residual noises\n",
    "        r_dn = self.dncnn_branch(x)\n",
    "        # Project into DnCNN feature space for FNet\n",
    "        feat = self.dncnn_branch.net[0:2](x)  # first conv+ReLU\n",
    "        feat = self.fnet_blocks(feat)\n",
    "        r_fnet = self.dncnn_branch.net[-1:](feat) if hasattr(self.dncnn_branch.net, '__getitem__') else nn.Conv2d(feat.size(1), x.size(1), 3, padding=1)(feat)\n",
    "        r_wave = self.wavelet_branch(x)\n",
    "        # Concatenate residuals and fuse\n",
    "        r_cat = torch.cat([r_dn, r_fnet, r_wave], dim=1)\n",
    "        r = self.fusion(r_cat)\n",
    "        # Subtract fused residual\n",
    "        return x - r\n",
    "\n",
    "# Example instantiation:\n",
    "# model = HybridTriBranchModel(channels=3, height=32, width=32)\n",
    "# Given an input tensor `noisy` of shape [B, 3, 32, 32],\n",
    "# `denoised = model(noisy)` will produce the cleaned output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridTriBranchModel(channels=3).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 20\n",
    "noise_std = 0.1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Epoch [1/20], Loss: 0.005254, Time: 136.89 sec\n",
      "Epoch [2/20], Loss: 0.001924, Time: 133.02 sec\n",
      "Epoch [3/20], Loss: 0.001744, Time: 145.09 sec\n",
      "Epoch [4/20], Loss: 0.001640, Time: 134.85 sec\n",
      "Epoch [5/20], Loss: 0.001592, Time: 135.01 sec\n",
      "Epoch [6/20], Loss: 0.001562, Time: 134.47 sec\n",
      "Epoch [7/20], Loss: 0.001538, Time: 134.53 sec\n",
      "Epoch [8/20], Loss: 0.001502, Time: 133.98 sec\n",
      "Epoch [9/20], Loss: 0.001445, Time: 133.77 sec\n",
      "Epoch [10/20], Loss: 0.001401, Time: 133.72 sec\n",
      "Epoch [11/20], Loss: 0.001381, Time: 132.76 sec\n",
      "Epoch [12/20], Loss: 0.001368, Time: 132.33 sec\n",
      "Epoch [13/20], Loss: 0.001354, Time: 132.03 sec\n",
      "Epoch [14/20], Loss: 0.001349, Time: 131.96 sec\n",
      "Epoch [15/20], Loss: 0.001343, Time: 132.16 sec\n",
      "Epoch [16/20], Loss: 0.001338, Time: 132.62 sec\n",
      "Epoch [17/20], Loss: 0.001334, Time: 131.48 sec\n",
      "Epoch [18/20], Loss: 0.001328, Time: 131.98 sec\n",
      "Epoch [19/20], Loss: 0.001325, Time: 131.57 sec\n",
      "Epoch [20/20], Loss: 0.001318, Time: 131.95 sec\n",
      "Loaded best model with lowest validation loss.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Training...\")\n",
    "model.train()  \n",
    "best_loss = float('inf')\n",
    "patience = 2  \n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for data, _ in train_loader:\n",
    "        data = data.to(device)  \n",
    "        noise = torch.randn_like(data) * noise_std\n",
    "        noisy_data = data + noise\n",
    "        output = model(noisy_data)\n",
    "        loss = criterion(output, data)\n",
    "        epoch_loss += loss.item() * data.size(0)\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()     \n",
    "        optimizer.step()       \n",
    "\n",
    "    epoch_loss /= len(train_dataset)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.6f}, Time: {elapsed:.2f} sec\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if epoch_loss < best_loss - 1e-6:  \n",
    "        best_loss = epoch_loss\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict() \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement. Patience: {patience_counter}/{patience}\")\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Loaded best model with lowest validation loss.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PSNR: 28.98 dB\n",
      "Test SSIM: 0.9213\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "psnr_list = []\n",
    "ssim_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, _ in test_loader:\n",
    "        data = data.to(device)\n",
    "        noise = torch.randn_like(data) * noise_std\n",
    "        noisy_data = data + noise\n",
    "        output = model(noisy_data)\n",
    "        \n",
    "        # Move tensors to CPU and convert to numpy arrays, clipping values into [0,1]\n",
    "        output_np = output.cpu().numpy().transpose(0, 2, 3, 1)   # (N, H, W, C)\n",
    "        clean_np  = data.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "        noisy_np  = noisy_data.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "        \n",
    "        # Calculate metrics image by image\n",
    "        for denoised, clean in zip(output_np, clean_np):\n",
    "            denoised = np.clip(denoised, 0., 1.)\n",
    "            clean = np.clip(clean, 0., 1.)\n",
    "            psnr_val = calculate_psnr(denoised, clean)\n",
    "            ssim_val = calculate_ssim(denoised, clean)\n",
    "            psnr_list.append(psnr_val)\n",
    "            ssim_list.append(ssim_val)\n",
    "\n",
    "mean_psnr = np.mean(psnr_list)\n",
    "mean_ssim = np.mean(ssim_list)\n",
    "\n",
    "print(f\"Test PSNR: {mean_psnr:.2f} dB\")\n",
    "print(f\"Test SSIM: {mean_ssim:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
