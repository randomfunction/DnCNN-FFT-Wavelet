{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                              \n",
    "import torch.nn as nn                      \n",
    "import torch.optim as optim                \n",
    "from torch.utils.data import DataLoader    \n",
    "import torchvision                       \n",
    "import torchvision.transforms as transforms \n",
    "import numpy as np                         \n",
    "import cv2                                \n",
    "from skimage.metrics import structural_similarity as ssim  \n",
    "import matplotlib.pyplot as plt           \n",
    "import time\n",
    "from pytorch_wavelets import DWT, IDWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(denoised, ground_truth):\n",
    "    mse = np.mean((denoised - ground_truth) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    PIXEL_MAX = 1.0 \n",
    "    psnr = 20 * np.log10(PIXEL_MAX / np.sqrt(mse))\n",
    "    return psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "\n",
    "def calculate_ssim(denoised, ground_truth):\n",
    "    return ssim(ground_truth, denoised, data_range=ground_truth.max() - ground_truth.min(), win_size=7, channel_axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Predicts the noise residual in the wavelet domain.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, wavelet='haar'):\n",
    "        super().__init__()\n",
    "        # Forward and inverse DWT (single level)\n",
    "        self.dwt = DWT(J=1, wave=wavelet)\n",
    "        self.idwt = IDWT(wave=wavelet)\n",
    "\n",
    "        # Feed-forward in wavelet domain\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Conv2d(4 * channels, 4 * channels, kernel_size=1, padding=0),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4 * channels, 4 * channels, kernel_size=1, padding=0),\n",
    "        )\n",
    "\n",
    "        # Learnable soft-thresholds for LH, HL, HH bands\n",
    "        # Shape: [3 (bands), channels, 1, 1]\n",
    "        self.threshold = nn.Parameter(torch.zeros(3, channels, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, C, H, W]\n",
    "        ll, yh = self.dwt(x)\n",
    "        # yh is a list of length J; for J=1, yh[0] has shape [B, C, 3, H/2, W/2]\n",
    "        detail = yh[0]\n",
    "        # Split into subbands\n",
    "        lh, hl, hh = torch.unbind(detail, dim=2)\n",
    "\n",
    "        # Concatenate lowpass and highpass subbands along channel dim\n",
    "        stacked = torch.cat([ll, lh, hl, hh], dim=1)\n",
    "        y = self.ffn(stacked)\n",
    "\n",
    "        # Split FFN output back into subbands\n",
    "        c = x.size(1)\n",
    "        ll2, lh2, hl2, hh2 = torch.split(y, c, dim=1)\n",
    "\n",
    "        # Apply learnable soft-threshold to high-frequency bands\n",
    "        t = torch.sigmoid(self.threshold)\n",
    "        lh2 = lh2 * t[0]\n",
    "        hl2 = hl2 * t[1]\n",
    "        hh2 = hh2 * t[2]\n",
    "\n",
    "        # Re-stack into shape expected by IDWT: [B, C, 3, H/2, W/2]\n",
    "        y_high = torch.stack([lh2, hl2, hh2], dim=2)\n",
    "\n",
    "        # Reconstruct residual from wavelet coefficients\n",
    "        # IDWT expects a tuple (lowpass, [highpass_list])\n",
    "        out = self.idwt((ll2, [y_high]))\n",
    "        return out  # residual noise prediction\n",
    "\n",
    "class HybridDnCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Combines standard DnCNN residual prediction with a wavelet-based residual branch.\n",
    "    Input: noisy image x\n",
    "    Output: denoised image\n",
    "    \"\"\"\n",
    "    def __init__(self, channels=3, num_layers=17, features=64, wavelet='haar'):\n",
    "        super(HybridDnCNN, self).__init__()\n",
    "        # Standard DnCNN branch\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        for _ in range(num_layers - 2):\n",
    "            layers += [\n",
    "                nn.Conv2d(features, features, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "        layers.append(nn.Conv2d(features, channels, kernel_size=3, padding=1, bias=False))\n",
    "        self.dncnn = nn.Sequential(*layers)\n",
    "\n",
    "        # Wavelet residual branch\n",
    "        self.wavelet_block = WaveletBlock(channels, wavelet)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Predict residual noise via DnCNN\n",
    "        noise_dn = self.dncnn(x)\n",
    "        # Predict residual noise via WaveletBlock\n",
    "        noise_wave = self.wavelet_block(x)\n",
    "        # Combine residual predictions\n",
    "        noise_combined = noise_dn + noise_wave\n",
    "        # Subtract noise from input to get denoised output\n",
    "        clean = x - noise_combined\n",
    "        return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download and load the CIFAR-10 training and test datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader  = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridDnCNN(channels=3).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 20\n",
    "noise_std = 0.1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Epoch [1/20], Loss: 0.008989, Time: 102.82 sec\n",
      "Epoch [2/20], Loss: 0.003195, Time: 85.25 sec\n",
      "Epoch [3/20], Loss: 0.002378, Time: 88.75 sec\n",
      "Epoch [4/20], Loss: 0.002063, Time: 84.14 sec\n",
      "Epoch [5/20], Loss: 0.001862, Time: 86.15 sec\n",
      "Epoch [6/20], Loss: 0.001759, Time: 80.57 sec\n",
      "Epoch [7/20], Loss: 0.001692, Time: 80.86 sec\n",
      "Epoch [8/20], Loss: 0.001664, Time: 81.26 sec\n",
      "Epoch [9/20], Loss: 0.001632, Time: 81.00 sec\n",
      "Epoch [10/20], Loss: 0.001603, Time: 82.57 sec\n",
      "Epoch [11/20], Loss: 0.001590, Time: 89.32 sec\n",
      "Epoch [12/20], Loss: 0.001564, Time: 87.07 sec\n",
      "Epoch [13/20], Loss: 0.001569, Time: 83.47 sec\n",
      "No improvement. Patience: 1/2\n",
      "Epoch [14/20], Loss: 0.001531, Time: 82.51 sec\n",
      "Epoch [15/20], Loss: 0.001533, Time: 83.37 sec\n",
      "No improvement. Patience: 1/2\n",
      "Epoch [16/20], Loss: 0.001519, Time: 88.35 sec\n",
      "Epoch [17/20], Loss: 0.001500, Time: 83.30 sec\n",
      "Epoch [18/20], Loss: 0.001494, Time: 80.74 sec\n",
      "Epoch [19/20], Loss: 0.001468, Time: 81.02 sec\n",
      "Epoch [20/20], Loss: 0.001483, Time: 80.08 sec\n",
      "No improvement. Patience: 1/2\n",
      "Loaded best model with lowest validation loss.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Training...\")\n",
    "model.train()  \n",
    "best_loss = float('inf')\n",
    "patience = 2  \n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for data, _ in train_loader:\n",
    "        data = data.to(device)  \n",
    "        noise = torch.randn_like(data) * noise_std\n",
    "        noisy_data = data + noise\n",
    "        output = model(noisy_data)\n",
    "        loss = criterion(output, data)\n",
    "        epoch_loss += loss.item() * data.size(0)\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()     \n",
    "        optimizer.step()       \n",
    "\n",
    "    epoch_loss /= len(train_dataset)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.6f}, Time: {elapsed:.2f} sec\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if epoch_loss < best_loss - 1e-6:  \n",
    "        best_loss = epoch_loss\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict() \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement. Patience: {patience_counter}/{patience}\")\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Loaded best model with lowest validation loss.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PSNR: 28.47 dB\n",
      "Test SSIM: 0.9149\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "psnr_list = []\n",
    "ssim_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, _ in test_loader:\n",
    "        data = data.to(device)\n",
    "        noise = torch.randn_like(data) * noise_std\n",
    "        noisy_data = data + noise\n",
    "        output = model(noisy_data)\n",
    "        \n",
    "        # Move tensors to CPU and convert to numpy arrays, clipping values into [0,1]\n",
    "        output_np = output.cpu().numpy().transpose(0, 2, 3, 1)   # (N, H, W, C)\n",
    "        clean_np  = data.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "        noisy_np  = noisy_data.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "        \n",
    "        # Calculate metrics image by image\n",
    "        for denoised, clean in zip(output_np, clean_np):\n",
    "            denoised = np.clip(denoised, 0., 1.)\n",
    "            clean = np.clip(clean, 0., 1.)\n",
    "            psnr_val = calculate_psnr(denoised, clean)\n",
    "            ssim_val = calculate_ssim(denoised, clean)\n",
    "            psnr_list.append(psnr_val)\n",
    "            ssim_list.append(ssim_val)\n",
    "\n",
    "mean_psnr = np.mean(psnr_list)\n",
    "mean_ssim = np.mean(ssim_list)\n",
    "\n",
    "print(f\"Test PSNR: {mean_psnr:.2f} dB\")\n",
    "print(f\"Test SSIM: {mean_ssim:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
