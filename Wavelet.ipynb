{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                              \n",
    "import torch.nn as nn                      \n",
    "import torch.optim as optim                \n",
    "from torch.utils.data import DataLoader    \n",
    "import torchvision                       \n",
    "import torchvision.transforms as transforms \n",
    "import numpy as np                         \n",
    "import cv2                                \n",
    "from skimage.metrics import structural_similarity as ssim  \n",
    "import matplotlib.pyplot as plt           \n",
    "import time\n",
    "from pytorch_wavelets import DWT, IDWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psnr(denoised, ground_truth):\n",
    "    mse = np.mean((denoised - ground_truth) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    PIXEL_MAX = 1.0 \n",
    "    psnr = 20 * np.log10(PIXEL_MAX / np.sqrt(mse))\n",
    "    return psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "\n",
    "def calculate_ssim(denoised, ground_truth):\n",
    "    return ssim(ground_truth, denoised, data_range=ground_truth.max() - ground_truth.min(), win_size=7, channel_axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Predicts the noise residual in the wavelet domain.\n",
    "    Uses DWT (Discrete Wavelet Transform) to analyze image in frequency + spatial domain.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, wavelet='haar'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Forward and inverse wavelet transforms (1-level decomposition)\n",
    "        self.dwt = DWT(J=1, wave=wavelet)\n",
    "        self.idwt = IDWT(wave=wavelet)\n",
    "\n",
    "        # Feed-forward network to process wavelet features (all 4 subbands)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Conv2d(4 * channels, 4 * channels, kernel_size=1, padding=0),  # Project + mix across channels\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4 * channels, 4 * channels, kernel_size=1, padding=0)   # Final projection\n",
    "        )\n",
    "\n",
    "        # Learnable soft-thresholding parameters for LH, HL, HH bands\n",
    "        self.threshold = nn.Parameter(torch.zeros(3, channels, 1, 1))  # Shape: [3 subbands, C, 1, 1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply Discrete Wavelet Transform\n",
    "        ll, yh = self.dwt(x)           # ll: low-frequency approx, yh: list of high-freq details\n",
    "\n",
    "        detail = yh[0]                 # Extract the first-level detail subbands\n",
    "        lh, hl, hh = torch.unbind(detail, dim=2)  # Separate into LH, HL, HH components\n",
    "\n",
    "        # Concatenate all 4 bands (LL, LH, HL, HH) for processing\n",
    "        stacked = torch.cat([ll, lh, hl, hh], dim=1)\n",
    "\n",
    "        # Pass through feedforward projection network\n",
    "        y = self.ffn(stacked)\n",
    "\n",
    "        c = x.size(1)  # Number of channels\n",
    "\n",
    "        # Split the processed features back into subbands\n",
    "        ll2, lh2, hl2, hh2 = torch.split(y, c, dim=1)\n",
    "\n",
    "        # Apply learnable soft-thresholding to high-frequency bands\n",
    "        t = torch.sigmoid(self.threshold)  # Thresholds in [0, 1] range\n",
    "        lh2 = lh2 * t[0]\n",
    "        hl2 = hl2 * t[1]\n",
    "        hh2 = hh2 * t[2]\n",
    "\n",
    "        # Stack high-frequency bands back into required shape for IDWT: [B, C, 3, H/2, W/2]\n",
    "        y_high = torch.stack([lh2, hl2, hh2], dim=2)\n",
    "\n",
    "        # Apply inverse DWT to get back to spatial domain (predicted residual noise)\n",
    "        out = self.idwt((ll2, [y_high]))\n",
    "        return out  # Final residual noise prediction from wavelet block\n",
    "\n",
    "\n",
    "class HybridDnCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Combines standard DnCNN residual prediction with a wavelet-based residual branch.\n",
    "    Input: noisy image x\n",
    "    Output: denoised image\n",
    "    \"\"\"\n",
    "    def __init__(self, channels=3, num_layers=17, features=64, wavelet='haar'):\n",
    "        super(HybridDnCNN, self).__init__()\n",
    "        # Standard DnCNN branch\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels=channels, out_channels=features, kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        for _ in range(num_layers - 2):\n",
    "            layers += [\n",
    "                nn.Conv2d(features, features, kernel_size=3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "        layers.append(nn.Conv2d(features, channels, kernel_size=3, padding=1, bias=False))\n",
    "        self.dncnn = nn.Sequential(*layers)\n",
    "\n",
    "        # Wavelet residual branch\n",
    "        self.wavelet_block = WaveletBlock(channels, wavelet)\n",
    "\n",
    "    def forward(self, x):\n",
    "        noise_dn = self.dncnn(x)\n",
    "        noise_wave = self.wavelet_block(x)\n",
    "        noise_combined = noise_dn + noise_wave\n",
    "        clean = x - noise_combined\n",
    "        return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download and load the CIFAR-10 training and test datasets\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class ImageFolderNoClass(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.file_paths = [os.path.join(folder_path, f) \n",
    "                           for f in os.listdir(folder_path) \n",
    "                           if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.file_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, 0\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((32,32))\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolderNoClass('./BSD500/train', transform=transform)\n",
    "val_dataset   = ImageFolderNoClass('./BSD500/val', transform=transform)\n",
    "test_dataset  = ImageFolderNoClass('./BSD500/test', transform=transform)\n",
    "\n",
    "# batch_size = 32\n",
    "# train_loader = DataLoader(train_dataset+val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(train_dataset+val_dataset+test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "print(repr(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HybridDnCNN(channels=3).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_epochs = 100\n",
    "noise_std = 0.1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Epoch [1/100], Loss: 2.860587, Time: 80.38 sec\n",
      "Epoch [2/100], Loss: 1.083148, Time: 72.84 sec\n",
      "Epoch [3/100], Loss: 0.690991, Time: 73.10 sec\n",
      "Epoch [4/100], Loss: 0.570792, Time: 73.30 sec\n",
      "Epoch [5/100], Loss: 0.494640, Time: 73.15 sec\n",
      "Epoch [6/100], Loss: 0.456837, Time: 73.01 sec\n",
      "Epoch [7/100], Loss: 0.434533, Time: 75.68 sec\n",
      "Epoch [8/100], Loss: 0.417939, Time: 72.06 sec\n",
      "Epoch [9/100], Loss: 0.408424, Time: 71.93 sec\n",
      "Epoch [10/100], Loss: 0.404299, Time: 71.97 sec\n",
      "Epoch [11/100], Loss: 0.391720, Time: 71.40 sec\n",
      "Epoch [12/100], Loss: 0.387643, Time: 72.57 sec\n",
      "Epoch [13/100], Loss: 0.384211, Time: 72.35 sec\n",
      "Epoch [14/100], Loss: 0.378280, Time: 72.77 sec\n",
      "Epoch [15/100], Loss: 0.372295, Time: 73.28 sec\n",
      "Epoch [16/100], Loss: 0.371394, Time: 73.69 sec\n",
      "Epoch [17/100], Loss: 0.369361, Time: 72.70 sec\n",
      "Epoch [18/100], Loss: 0.365060, Time: 72.60 sec\n",
      "Epoch [19/100], Loss: 0.362386, Time: 72.70 sec\n",
      "Epoch [20/100], Loss: 0.360790, Time: 72.71 sec\n",
      "Epoch [21/100], Loss: 0.360958, Time: 72.75 sec\n",
      "No improvement. Patience: 1/2\n",
      "Epoch [22/100], Loss: 0.356350, Time: 72.53 sec\n",
      "Epoch [23/100], Loss: 0.361386, Time: 74.45 sec\n",
      "No improvement. Patience: 1/2\n",
      "Epoch [24/100], Loss: 0.355367, Time: 74.26 sec\n",
      "Epoch [25/100], Loss: 0.350550, Time: 73.23 sec\n",
      "Epoch [26/100], Loss: 0.350023, Time: 70.26 sec\n",
      "Epoch [27/100], Loss: 0.348032, Time: 72.77 sec\n",
      "Epoch [28/100], Loss: 0.348194, Time: 72.67 sec\n",
      "No improvement. Patience: 1/2\n",
      "Epoch [29/100], Loss: 0.454783, Time: 73.84 sec\n",
      "No improvement. Patience: 2/2\n",
      "Early stopping triggered.\n",
      "Loaded best model with lowest validation loss.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Training...\")\n",
    "model.train()  \n",
    "best_loss = float('inf')\n",
    "patience = 2  \n",
    "patience_counter = 0\n",
    "best_model_state = None\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    for data,_ in train_loader:\n",
    "        data = data.to(device)  \n",
    "        noise = torch.randn_like(data) * noise_std\n",
    "        noisy_data = data + noise\n",
    "        output = model(noisy_data)\n",
    "        loss = criterion(output, data)\n",
    "        epoch_loss += loss.item() * data.size(0)\n",
    "\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()     \n",
    "        optimizer.step()       \n",
    "\n",
    "    epoch_loss /= len(train_dataset)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.6f}, Time: {elapsed:.2f} sec\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if epoch_loss < best_loss - 1e-6:  \n",
    "        best_loss = epoch_loss\n",
    "        patience_counter = 0\n",
    "        best_model_state = model.state_dict() \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement. Patience: {patience_counter}/{patience}\")\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Loaded best model with lowest validation loss.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test PSNR: 28.15 dB\n",
      "Test SSIM: 0.8793\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "psnr_list = []\n",
    "ssim_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data,_ in test_loader:\n",
    "        data = data.to(device)\n",
    "        noise = torch.randn_like(data) * noise_std\n",
    "        noisy_data = data + noise\n",
    "        output = model(noisy_data)\n",
    "        \n",
    "        # Move tensors to CPU and convert to numpy arrays, clipping values into [0,1]\n",
    "        output_np = output.cpu().numpy().transpose(0, 2, 3, 1)   # (N, H, W, C)\n",
    "        clean_np  = data.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "        noisy_np  = noisy_data.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "        \n",
    "        # Calculate metrics image by image\n",
    "        for denoised, clean in zip(output_np, clean_np):\n",
    "            denoised = np.clip(denoised, 0., 1.)\n",
    "            clean = np.clip(clean, 0., 1.)\n",
    "            psnr_val = calculate_psnr(denoised, clean)\n",
    "            ssim_val = calculate_ssim(denoised, clean)\n",
    "            psnr_list.append(psnr_val)\n",
    "            ssim_list.append(ssim_val)\n",
    "\n",
    "mean_psnr = np.mean(psnr_list)\n",
    "mean_ssim = np.mean(ssim_list)\n",
    "\n",
    "print(f\"Test PSNR: {mean_psnr:.2f} dB\")\n",
    "print(f\"Test SSIM: {mean_ssim:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
